{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tristantorchet/Desktop/Code/VSCode/LearningJAX/Flax\n",
      "/Users/tristantorchet/Desktop/Code/VSCode/LearningJAX/.venv/bin/python\n",
      "flax==0.8.0\n",
      "jax==0.4.25\n",
      "jaxlib==0.4.25\n",
      "jaxtyping==0.2.36\n",
      "optax==0.1.8\n",
      "orbax-checkpoint==0.5.0\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!which python\n",
    "!pip freeze | grep -E 'flax|jax|orbax|optax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import numpy as np\n",
    "import torch\n",
    "from jax import numpy as jnp\n",
    "from torch.utils.data import TensorDataset\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from flax import linen as nn\n",
    "from jax.nn.initializers import lecun_normal\n",
    "from typing import Any, Tuple, Sequence, Optional\n",
    "\n",
    "jnp.set_printoptions(precision=3, suppress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: this code is from QSSM project and won't be updated \n",
    "def create_mnist_classification_dataset(bsz=128, root=\"./data\"):\n",
    "    print(\"[*] Generating MNIST Classification Dataset...\")\n",
    "\n",
    "    # Constants\n",
    "    SEQ_LENGTH, N_CLASSES, IN_DIM = 784, 10, 1\n",
    "    tf = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=0.5, std=0.5),\n",
    "            transforms.Lambda(lambda x: x.view(IN_DIM, SEQ_LENGTH).t()),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    train = torchvision.datasets.MNIST(\n",
    "        root, train=True, download=True, transform=tf\n",
    "    )\n",
    "    test = torchvision.datasets.MNIST(\n",
    "        root, train=False, download=True, transform=tf\n",
    "    )\n",
    "\n",
    "    def custom_collate_fn(batch):\n",
    "        transposed_data = list(zip(*batch))\n",
    "        labels = np.array(transposed_data[1])\n",
    "        images = np.array(transposed_data[0])\n",
    "\n",
    "        return images, labels       \n",
    "\n",
    "\n",
    "    # Return data loaders, with the provided batch size\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        train, batch_size=bsz, shuffle=True, collate_fn=custom_collate_fn\n",
    "    )\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        test, batch_size=bsz, shuffle=False, collate_fn=custom_collate_fn\n",
    "    )\n",
    "\n",
    "    return trainloader, testloader, N_CLASSES, SEQ_LENGTH, IN_DIM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Generating MNIST Classification Dataset...\n"
     ]
    }
   ],
   "source": [
    "trainloader, testloader, N_CLASSES, SEQ_LENGTH, IN_DIM = create_mnist_classification_dataset(root=\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 784, 1) (128,)\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "batch_x, batch_y = next(iter(testloader))\n",
    "print(batch_x.shape, batch_y.shape)\n",
    "print(batch_y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "class RNNCell(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, state, x):\n",
    "        # Wh @ h + Wx @ x + b can be efficiently computed\n",
    "        # by concatenating the vectors and then having a single dense layer\n",
    "        x = jnp.concatenate([state, x])\n",
    "        new_state = jnp.tanh(nn.Dense(state.shape[0], name='Dense_RNN')(x))\n",
    "        return new_state\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    hidden_size: int\n",
    "    output_size: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        rnn_cell = RNNCell()\n",
    "        state = jnp.zeros((self.hidden_size,))\n",
    "        dense_out = nn.Dense(self.output_size, name='Dense_Out')\n",
    "        # out_ = []\n",
    "        for t in range(x.shape[0]):\n",
    "            state = rnn_cell(state, x[t])\n",
    "            out = dense_out(state)\n",
    "        #     # if we want to track at each time step, otherwize only the last one is enough\n",
    "        #     out_.append(out)\n",
    "        # out = jnp.stack(out_)\n",
    "        return out\n",
    "    \n",
    "BatchRNN = nn.vmap(RNN, in_axes=0, out_axes=0, variable_axes={'params': 0}, split_rngs={'params': False})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srn = BatchRNN(256, 10)\n",
    "variables = srn.init(jax.random.PRNGKey(0), jnp.zeros((1,784,1)))\n",
    "y = srn.apply(variables, jnp.zeros((1,784,1)))\n",
    "y.shape # (batch, time, cell_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax.training import train_state\n",
    "import optax\n",
    "\n",
    "\n",
    "# def create_train_state(key, model_cls, lr):\n",
    "#     '''\n",
    "#     Create the training state for the model.\n",
    "#     '''\n",
    "#     model = model_cls(hidden_size=64, output_size=10)\n",
    "#     init_x = jnp.ones((1, 784, 1))  # Example batch of inputs\n",
    "\n",
    "#     params = model.init(key, init_x)['params']\n",
    "#     print(\"Initialized parameter structure:\", jax.tree_util.tree_map(jnp.shape, params))\n",
    "#     # use adam \n",
    "#     optimizer = optax.sgd(learning_rate=lr, momentum=0.9)\n",
    "#     return train_state.TrainState.create(apply_fn=model.apply, params=params, tx=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "key, subkey = jax.random.split(key)\n",
    "lr = 1e-2\n",
    "# state = create_train_state(subkey, RNN, lr)\n",
    "# print(state.params.keys())\n",
    "# print(state.params['RNNCell_0'])\n",
    "# print(state.params['Dense_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(state.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(state.params['Dense_0']['kernel'].shape)\n",
    "# print(state.params['Dense_0']['bias'].shape)\n",
    "# print(train_state.params['output']['kernel'].shape)\n",
    "# print(train_state.params['output']['bias'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def update_model(state, grads):\n",
    "    return state.apply_gradients(grads=grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model(state, images, labels):\n",
    "    \"\"\"Computes gradients, loss and accuracy for a single batch.\"\"\"\n",
    "\n",
    "    def loss_fn(params):\n",
    "        logits = state.apply_fn({'params': params}, images)\n",
    "        one_hot = jax.nn.one_hot(labels, 10)\n",
    "        loss = jnp.mean(optax.softmax_cross_entropy(logits=logits, labels=one_hot))\n",
    "        return loss, logits\n",
    "\n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (loss, logits), grads = grad_fn(state.params)\n",
    "    accuracy = jnp.mean(jnp.argmax(logits, -1) == labels)\n",
    "    return grads, loss, accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(state, train_dl, rng):\n",
    "    \"\"\"Train for a single epoch.\"\"\"\n",
    "\n",
    "    epoch_loss = []\n",
    "    epoch_accuracy = []\n",
    "\n",
    "    progress_bar = tqdm(train_dl, desc=\"Training\", leave=True)\n",
    "    batch_id = 0\n",
    "    for batch_images, batch_labels in progress_bar:\n",
    "        grads, loss, accuracy = apply_model(state, batch_images, batch_labels)\n",
    "        # print(jnp.max(grads['dense_0']['kernel']), jnp.min(grads['dense_0']['kernel']))\n",
    "        # print(loss)\n",
    "        state = update_model(state, grads)\n",
    "        epoch_loss.append(loss)\n",
    "        epoch_accuracy.append(accuracy)\n",
    "        batch_id += 1\n",
    "        if batch_id % 3 == 0:\n",
    "            progress_bar.set_postfix(loss=loss.item(), accuracy=accuracy.item())\n",
    "        \n",
    "    train_loss = np.mean(epoch_loss)\n",
    "    train_accuracy = np.mean(epoch_accuracy)\n",
    "    return state, train_loss, train_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_state(key, model_cls, lr):\n",
    "    init_x = jnp.ones((128, 784, 1))  # Example batch of inputs\n",
    "\n",
    "    model = model_cls(hidden_size=256, output_size=10)\n",
    "    params = model.init(key, init_x)['params']\n",
    "    \n",
    "    # Debugging: Print parameter structure\n",
    "\n",
    "    optimizer = optax.adam(lr)\n",
    "    return train_state.TrainState.create(\n",
    "        apply_fn=model.apply,\n",
    "        params=params,\n",
    "        tx=optimizer,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = create_train_state(key, BatchRNN, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 14/469 [02:50<1:32:22, 12.18s/it, accuracy=0.117, loss=4.54] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m30\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     state, train_loss, train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_accuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[47], line 10\u001b[0m, in \u001b[0;36mrun_epoch\u001b[0;34m(state, train_dl, rng)\u001b[0m\n\u001b[1;32m      8\u001b[0m batch_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_images, batch_labels \u001b[38;5;129;01min\u001b[39;00m progress_bar:\n\u001b[0;32m---> 10\u001b[0m     grads, loss, accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mapply_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# print(jnp.max(grads['dense_0']['kernel']), jnp.min(grads['dense_0']['kernel']))\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# print(loss)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     state \u001b[38;5;241m=\u001b[39m update_model(state, grads)\n",
      "Cell \u001b[0;32mIn[46], line 11\u001b[0m, in \u001b[0;36mapply_model\u001b[0;34m(state, images, labels)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss, logits\n\u001b[1;32m     10\u001b[0m grad_fn \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mvalue_and_grad(loss_fn, has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 11\u001b[0m (loss, logits), grads \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mmean(jnp\u001b[38;5;241m.\u001b[39margmax(logits, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m labels)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grads, loss, accuracy\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/Code/VSCode/LearningJAX/.venv/lib/python3.12/site-packages/jax/_src/api.py:751\u001b[0m, in \u001b[0;36mvalue_and_grad.<locals>.value_and_grad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    749\u001b[0m _check_scalar(ans)\n\u001b[1;32m    750\u001b[0m tree_map(partial(_check_output_dtype_grad, holomorphic), ans)\n\u001b[0;32m--> 751\u001b[0m g \u001b[38;5;241m=\u001b[39m \u001b[43mvjp_py\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlax_internal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mans\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    752\u001b[0m g \u001b[38;5;241m=\u001b[39m g[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(argnums, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m g\n\u001b[1;32m    753\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_aux:\n",
      "File \u001b[0;32m~/Desktop/Code/VSCode/LearningJAX/.venv/lib/python3.12/site-packages/jax/_src/tree_util.py:488\u001b[0m, in \u001b[0;36m_HashableCallableShim.__call__\u001b[0;34m(self, *args, **kw)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m--> 488\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Code/VSCode/LearningJAX/.venv/lib/python3.12/site-packages/jax/_src/api.py:2163\u001b[0m, in \u001b[0;36m_vjp_pullback_wrapper\u001b[0;34m(name, cotangent_dtypes, cotangent_shapes, io_tree, fun, *py_args_)\u001b[0m\n\u001b[1;32m   2158\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mshape(arg) \u001b[38;5;241m!=\u001b[39m ct_shape:\n\u001b[1;32m   2159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of cotangent input to vjp pullback function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mshape(arg)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmust be the same as the shape of corresponding primal input \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2162\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mct_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2163\u001b[0m ans \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten(out_tree, ans)\n",
      "File \u001b[0;32m~/Desktop/Code/VSCode/LearningJAX/.venv/lib/python3.12/site-packages/jax/_src/tree_util.py:488\u001b[0m, in \u001b[0;36m_HashableCallableShim.__call__\u001b[0;34m(self, *args, **kw)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m--> 488\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Code/VSCode/LearningJAX/.venv/lib/python3.12/site-packages/jax/_src/interpreters/ad.py:150\u001b[0m, in \u001b[0;36mvjp.<locals>.unbound_vjp\u001b[0;34m(pvals, jaxpr, consts, *cts)\u001b[0m\n\u001b[1;32m    148\u001b[0m cts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(ct \u001b[38;5;28;01mfor\u001b[39;00m ct, pval \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(cts, pvals) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pval\u001b[38;5;241m.\u001b[39mis_known())\n\u001b[1;32m    149\u001b[0m dummy_args \u001b[38;5;241m=\u001b[39m [UndefinedPrimal(v\u001b[38;5;241m.\u001b[39maval) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m jaxpr\u001b[38;5;241m.\u001b[39minvars]\n\u001b[0;32m--> 150\u001b[0m arg_cts \u001b[38;5;241m=\u001b[39m \u001b[43mbackward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(instantiate_zeros, arg_cts)\n",
      "File \u001b[0;32m~/Desktop/Code/VSCode/LearningJAX/.venv/lib/python3.12/site-packages/jax/_src/interpreters/ad.py:261\u001b[0m, in \u001b[0;36mbackward_pass\u001b[0;34m(jaxpr, reduce_axes, transform_stack, consts, primals_in, cotangents_in)\u001b[0m\n\u001b[1;32m    259\u001b[0m       cts_out \u001b[38;5;241m=\u001b[39m [Zero(v\u001b[38;5;241m.\u001b[39maval) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m eqn\u001b[38;5;241m.\u001b[39minvars] \u001b[38;5;28;01mif\u001b[39;00m cts_out \u001b[38;5;129;01mis\u001b[39;00m Zero \u001b[38;5;28;01melse\u001b[39;00m cts_out\n\u001b[1;32m    260\u001b[0m       \u001b[38;5;66;03m# FIXME: Some invars correspond to primals!\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m       \u001b[38;5;28mmap\u001b[39m(\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrite_cotangent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meqn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprimitive\u001b[49m\u001b[43m)\u001b[49m, eqn\u001b[38;5;241m.\u001b[39minvars, cts_out)\n\u001b[1;32m    263\u001b[0m cotangents_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(read_cotangent, jaxpr\u001b[38;5;241m.\u001b[39minvars)\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cotangents_out\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    state, train_loss, train_accuracy = run_epoch(state, trainloader, key)\n",
    "    print(f\"Epoch {epoch} | Loss: {train_loss} | Accuracy: {train_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
