{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a Custom Elman RNN for MNIST Classification (row and sequential)\n",
    "\n",
    "In this notebook, we implement a **custom Elman RNN** to classify the **MNIST dataset** in both **row-wise** and **sequential** formats.\n",
    "\n",
    "### Overview of the Implementation:\n",
    "We define two key components:\n",
    "1. ````CustomRNNLayer```` – A single-layer recurrent neural network (Elman RNN).\n",
    "2. ````RNNBackbone```` – A full RNN-based model that stacks one or more `CustomRNNLayer` instances and adds a ```final linear layer``` to classify MNIST digits.\n",
    "\n",
    "---\n",
    "\n",
    "## Optimizing Computation for Efficiency\n",
    "\n",
    "One common bottleneck in RNN implementations is the repeated matrix multiplication inside the loop. To optimize this, we leverage the following observation:\n",
    "\n",
    "### Key Idea:\n",
    "When multiplying a matrix ```W``` of shape ```(input_size, hidden_size)``` with an input tensor ```x```, each row of ```x``` undergoes the same transformation. Instead of computing ```x_t @ W``` separately for each time step ```t```, we can **precompute the entire transformation** outside the loop.\n",
    "\n",
    "For an input ```x``` of shape ```(batch_size, seq_len, input_size)```, conceptually, we can think of it as a collection of individual ```(input_size,)``` vectors, each of which gets multiplied by ```W```. Instead of performing these multiplications step by step inside the loop, we **batch the operation** in one go:\n",
    "\n",
    "$$\n",
    "\\~x = x @ W\n",
    "$$\n",
    "\n",
    "This provides the transformed values for all time steps at once, which we can then slice efficiently within the loop.\n",
    "\n",
    "### What This Means in Practice:\n",
    "Instead of performing ```x_t @ W``` at every time step ```t```, we:\n",
    "1. ```Precompute``` the full transformation ```x_tilde = x @ W``` before entering the loop.\n",
    "2. ```Slice``` the corresponding row at each time step ```t```.\n",
    "\n",
    "This avoids redundant computation and significantly speeds up the RNN execution.\n",
    "\n",
    "### Code Comparison:\n",
    "- **Previous (Less Efficient) Approach**:  \n",
    "  Each time step computes ```x_t @ W`` inside the loop.\n",
    "- **Optimized Approach**:\n",
    "  We precompute ```x_tilde = x @ W``` once and slice the result in the loop.\n",
    "\n",
    "This simple change leads to a **more efficient** implementation without altering the core behavior of the RNN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import sys \n",
    "sys.path.append('../Flax')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available\n",
      "NVIDIA GeForce RTX 4090\n",
      "cuda\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "    print(torch.cuda.get_device_name())\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(device)\n",
    "    print(torch.cuda.current_device())\n",
    "    print(torch.cuda.device_count())\n",
    "\n",
    "else:\n",
    "    print(\"CUDA is not available\")\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import create_mnist_classification_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Illustration of the matrix multiplication optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.,  2.],\n",
      "         [ 3.,  4.,  5.],\n",
      "         [ 6.,  7.,  8.]],\n",
      "\n",
      "        [[ 9., 10., 11.],\n",
      "         [12., 13., 14.],\n",
      "         [15., 16., 17.]],\n",
      "\n",
      "        [[18., 19., 20.],\n",
      "         [21., 22., 23.],\n",
      "         [24., 25., 26.]]])\n",
      "torch.Size([3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(0, 27).reshape(3,3,3)\n",
    "# change the dtype of the tensor\n",
    "a = a.type(torch.float32)\n",
    "print(a)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [1., 2., 3.],\n",
      "        [1., 2., 3.]])\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "b = torch.ones(3,3) * torch.tensor([1,2,3])\n",
    "print(b)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[  3.,   6.,   9.],\n",
      "         [ 12.,  24.,  36.],\n",
      "         [ 21.,  42.,  63.]],\n",
      "\n",
      "        [[ 30.,  60.,  90.],\n",
      "         [ 39.,  78., 117.],\n",
      "         [ 48.,  96., 144.]],\n",
      "\n",
      "        [[ 57., 114., 171.],\n",
      "         [ 66., 132., 198.],\n",
      "         [ 75., 150., 225.]]])\n"
     ]
    }
   ],
   "source": [
    "print(a @ b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Optimized Approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Generating MNIST Classification Dataset...\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "BATCH_SIZE = 128\n",
    "HIDDEN_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 10\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DATASET_VERSION = \"row\" # \"sequential\" or \"row\"\n",
    "\n",
    "# Create dataset\n",
    "train_loader, val_loader, test_loader, n_classes, seq_length, in_dim = create_mnist_classification_dataset(\n",
    "    bsz=BATCH_SIZE, version=DATASET_VERSION\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRNN(nn.Module):\n",
    "    '''\n",
    "    Custom RNN module with tanh activation.\n",
    "    This layer is run for each time step in the sequence.\n",
    "    It handles batched input the same way as nn.Linear does:\n",
    "    - x: [batch_size, seq_len, input_size]\n",
    "    - we access x_t for each time step t: x_t = x[:, t, :]\n",
    "    - It computes x_new = x_t @ W.T + b (batch_size, hidden_size) for each time step.\n",
    "    - W: [input_size, hidden_size]\n",
    "    '''\n",
    "    def __init__(self, input_size, hidden_size, output_size=10):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # Single weight matrices for the entire RNN\n",
    "        self.W_ih = nn.Linear(input_size, hidden_size, bias=True)\n",
    "        self.W_hh = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "        # self.W_out = nn.Linear(hidden_size, output_size, bias=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Processes a batch of sequences through the RNN.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor of shape [batch_size, seq_len, input_size]\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (state_history, output_history)\n",
    "                - state_history: Tensor of shape [batch_size, seq_len, hidden_size]\n",
    "                - output_history: Tensor of shape [batch_size, seq_len, output_size]\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "        device = x.device\n",
    "        \n",
    "        # Initialize hidden state\n",
    "        h = torch.zeros(batch_size, self.hidden_size, device=device)\n",
    "        \n",
    "        # Prepare tensors to store history\n",
    "        state_history = torch.zeros(batch_size, seq_len, self.hidden_size, device=device)\n",
    "        # output_history = torch.zeros(batch_size, seq_len, self.output_size, device=device)\n",
    "        \n",
    "        x_tilde = self.W_ih(x)\n",
    "        # Efficiently process the sequence using vectorized operations\n",
    "        for t in range(seq_len):\n",
    "            # Extract current input across all batches\n",
    "            x_t = x_tilde[:, t, :]\n",
    "            \n",
    "            # Combined operation: h = tanh(W_ih @ x_t + W_hh @ h)\n",
    "            h = torch.tanh(x_t + self.W_hh(h))\n",
    "            \n",
    "            # Calculate output\n",
    "            # y = torch.tanh(self.W_out(h))\n",
    "            \n",
    "            # Store states and outputs\n",
    "            state_history[:, t, :] = h\n",
    "            # output_history[:, t, :] = y\n",
    "        \n",
    "        return state_history #, output_history\n",
    "    \n",
    "# Create model\n",
    "class RNN(nn.Module):\n",
    "    '''\n",
    "    RNN backbone using 1 recurrent layer and 1 readout layer\n",
    "    '''\n",
    "    def __init__(self, input_size, hidden_size, output_size=10):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.input_size = input_size\n",
    "        self.rnn_layer = CustomRNN(input_size, hidden_size, output_size)\n",
    "        self.W_out = nn.Linear(hidden_size, output_size, bias=True)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: [seq_len, input_size] or [batch_size, seq_len, input_size]\n",
    "        \n",
    "        # state_hist, out_hist = self.rnn_layer(x)\n",
    "        state_hist = self.rnn_layer(x)\n",
    "        out_hist = self.W_out(state_hist)\n",
    "        return state_hist, out_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion, device='cuda'):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(tqdm(train_loader)):\n",
    "        # Convert numpy arrays to PyTorch tensors\n",
    "        inputs = torch.tensor(inputs, dtype=torch.float32).to(device)\n",
    "        targets = torch.tensor(targets, dtype=torch.long).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        _, outputs = model(inputs)\n",
    "        # Use the last output for classification\n",
    "        final_outputs = outputs[:, -1, :]\n",
    "        \n",
    "        loss = criterion(final_outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        _, predicted = final_outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "    \n",
    "    accuracy = 100.0 * correct / total\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    \n",
    "    return average_loss, accuracy\n",
    "\n",
    "def validate(model, val_loader, criterion, device='cuda'):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "            # Convert numpy arrays to PyTorch tensors\n",
    "            inputs = torch.tensor(inputs, dtype=torch.float32).to(device)\n",
    "            targets = torch.tensor(targets, dtype=torch.long).to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            _, outputs = model(inputs)\n",
    "            # Use the last output for classification\n",
    "            final_outputs = outputs[:, -1, :]\n",
    "            \n",
    "            loss = criterion(final_outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            _, predicted = final_outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    \n",
    "    accuracy = 100.0 * correct / total\n",
    "    average_loss = total_loss / len(val_loader)\n",
    "    \n",
    "    return average_loss, accuracy\n",
    "\n",
    "def test(model, test_loader, device='cuda'):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "            # Convert numpy arrays to PyTorch tensors\n",
    "            inputs = torch.tensor(inputs, dtype=torch.float32).to(device)\n",
    "            targets = torch.tensor(targets, dtype=torch.long).to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            _, outputs = model(inputs)\n",
    "            # Use the last output for classification\n",
    "            final_outputs = outputs[:, -1, :]\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            _, predicted = final_outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    \n",
    "    accuracy = 100.0 * correct / total\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:12<00:00, 37.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "Train Loss: 1.2272 | Train Acc: 57.12%\n",
      "Val Loss: 0.7780 | Val Acc: 74.83%\n",
      "Time: 13.78s\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:11<00:00, 41.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:\n",
      "Train Loss: 0.6493 | Train Acc: 79.77%\n",
      "Val Loss: 0.5507 | Val Acc: 83.94%\n",
      "Time: 12.45s\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 436/468 [00:09<00:00, 45.20it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Validation (using test set as validation in this case)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m val_loss, val_acc \u001b[38;5;241m=\u001b[39m validate(model, test_loader, criterion, DEVICE)\n",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, criterion, device)\u001b[0m\n\u001b[1;32m      4\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      5\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 7\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Convert numpy arrays to PyTorch tensors\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/.jax_conda_env_LearningJAX/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/.jax_conda_env_LearningJAX/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/.jax_conda_env_LearningJAX/lib/python3.12/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/.jax_conda_env_LearningJAX/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/.jax_conda_env_LearningJAX/lib/python3.12/site-packages/torchvision/datasets/mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/miniconda3/envs/.jax_conda_env_LearningJAX/lib/python3.12/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/miniconda3/envs/.jax_conda_env_LearningJAX/lib/python3.12/site-packages/torchvision/transforms/transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[1;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/.jax_conda_env_LearningJAX/lib/python3.12/site-packages/torchvision/transforms/functional.py:175\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    173\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mpermute((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mByteTensor):\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_float_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdiv(\u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = RNN(in_dim, HIDDEN_SIZE, n_classes).to(DEVICE)\n",
    "# model = CustomRNN(in_dim, HIDDEN_SIZE, n_classes).to(DEVICE)\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Training\n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, DEVICE)\n",
    "    \n",
    "    # Validation (using test set as validation in this case)\n",
    "    val_loss, val_acc = validate(model, test_loader, criterion, DEVICE)\n",
    "    \n",
    "    # Calculate epoch time\n",
    "    epoch_time = time.time() - start_time\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f'Epoch {epoch}/{EPOCHS}:')\n",
    "    print(f'Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%')\n",
    "    print(f'Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%')\n",
    "    print(f'Time: {epoch_time:.2f}s')\n",
    "    print('-' * 60)\n",
    "        \n",
    "# Final test\n",
    "test_acc = test(model, test_loader, DEVICE)\n",
    "print(f'Test Accuracy: {test_acc:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".jax_conda_env_LearningJAX",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
